\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{MultiVariate Analysis}{14}{chapter*.14}}
\newlabel{sec:unchapitre}{{3.3}{14}{MultiVariate Analysis}{chapter*.14}{}}
\newlabel{mva_multiple}{{4.7a}{14}{ROC curves of 5 bests MVA, these are almost overlapping.\relax }{figure.caption.15}{}}
\newlabel{sub@mva_multiple}{{a}{14}{ROC curves of 5 bests MVA, these are almost overlapping.\relax }{figure.caption.15}{}}
\newlabel{inv_mva_multiple}{{4.7b}{14}{Inverse ROC curve for the 5 bests MVA, on this plot BDT and ANN(MLPBNN) are clearly the two bests.\relax }{figure.caption.15}{}}
\newlabel{sub@inv_mva_multiple}{{b}{14}{Inverse ROC curve for the 5 bests MVA, on this plot BDT and ANN(MLPBNN) are clearly the two bests.\relax }{figure.caption.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces ROC curve for the 5 best MVA that has been tested. Receiver Operating Characteristic (ROC) curve reflects the discrimination power of a classifier. It is constructed by plotting the ratio of background rejection versus signal efficiency by varying a threshold on the MVA output.\relax }}{14}{figure.caption.15}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Artificial Neural Network}{14}{section.4.1}}
\newlabel{one_neuron}{{4.8a}{15}{Diagram of a single neuron algorithm.\relax }{figure.caption.16}{}}
\newlabel{sub@one_neuron}{{a}{15}{Diagram of a single neuron algorithm.\relax }{figure.caption.16}{}}
\newlabel{nn_arch}{{4.8b}{15}{Architecture of an artificial neural network with 4 input variables, one hidden layer, and one output neuron.\relax }{figure.caption.16}{}}
\newlabel{sub@nn_arch}{{b}{15}{Architecture of an artificial neural network with 4 input variables, one hidden layer, and one output neuron.\relax }{figure.caption.16}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Input set optimization}{15}{subsection.4.1.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces On the left : Input variable set optimization results overview for the "overlapping criteria" estimator. Each bin is the estimator value for one MVA. Except for the 1st column that represents the MVA trained with the whole input set (step 1), 2nd column represent MVA's that has been trained after removing one variable at a time (step 2), following columns are the iterations of step 2.  On the right : overview of the estimator value for each column (step 2). maximum value (red solid line), average value (dark blue solid line) and lowest value (light blue solid line).\relax }}{16}{figure.caption.17}}
\newlabel{input_optim}{{4.9}{16}{On the left : Input variable set optimization results overview for the "overlapping criteria" estimator. Each bin is the estimator value for one MVA. Except for the 1st column that represents the MVA trained with the whole input set (step 1), 2nd column represent MVA's that has been trained after removing one variable at a time (step 2), following columns are the iterations of step 2.\\ On the right : overview of the estimator value for each column (step 2). maximum value (red solid line), average value (dark blue solid line) and lowest value (light blue solid line).\relax }{figure.caption.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces Artificial Neural Network response with signal from test sample (blue histogram), background from test sample (red shaded histogram), signal from training sample (blue dots) and background from training sample (red dots). The good agreement between training and testing sample shows no overfitting (in the case where these sample are representative of the data).\relax }}{17}{figure.caption.18}}
\newlabel{nn_output}{{4.10}{17}{Artificial Neural Network response with signal from test sample (blue histogram), background from test sample (red shaded histogram), signal from training sample (blue dots) and background from training sample (red dots). The good agreement between training and testing sample shows no overfitting (in the case where these sample are representative of the data).\relax }{figure.caption.18}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Boosted Decision Tree}{17}{section.4.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.11}{\ignorespaces Boosted Decision Tree classifying in 5 classes diagram.\relax }}{17}{figure.caption.19}}
\newlabel{bdt_diagram}{{4.11}{17}{Boosted Decision Tree classifying in 5 classes diagram.\relax }{figure.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.12}{\ignorespaces Boosted Decision Tree response with signal from test sample (blue histogram), background from test sample (red shaded histogram), signal from training sample (blue dots) and background from training sample (red dots).\relax }}{18}{figure.caption.20}}
\newlabel{bdt_output}{{4.12}{18}{Boosted Decision Tree response with signal from test sample (blue histogram), background from test sample (red shaded histogram), signal from training sample (blue dots) and background from training sample (red dots).\relax }{figure.caption.20}{}}
\@setckpt{chapters/mva}{
\setcounter{page}{19}
\setcounter{equation}{0}
\setcounter{enumi}{0}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{1}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{4}
\setcounter{section}{2}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{12}
\setcounter{table}{0}
\setcounter{Item}{0}
\setcounter{Hfootnote}{1}
\setcounter{bookmark@seq@number}{18}
\setcounter{parentequation}{0}
\setcounter{ContinuedFloat}{0}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
\setcounter{float@type}{8}
\setcounter{algorithm}{0}
\setcounter{ALC@unique}{0}
\setcounter{ALC@line}{0}
\setcounter{ALC@rem}{0}
\setcounter{ALC@depth}{0}
\setcounter{definition}{0}
\setcounter{theoreme}{0}
\setcounter{remarque}{0}
\setcounter{propriete}{0}
\setcounter{exemple}{0}
\setcounter{section@level}{1}
}
